{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping da https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-categoria senza file excel"
      ],
      "metadata": {
        "id": "-f1avGJMTkTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL della pagina iniziale delle categorie di alimenti\n",
        "base_url = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-categoria\"\n",
        "\n",
        "# Funzione per ottenere il contenuto HTML di una pagina\n",
        "def get_html(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        print(f\"Errore {response.status_code} nella richiesta a {url}\")\n",
        "        return None\n",
        "\n",
        "# Funzione per estrarre i link delle ricette\n",
        "def get_recipe_links(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/tabelle-nutrizionali/'):\n",
        "            recipe_links.append(href)\n",
        "    return recipe_links[:3]  # Limita ai primi 3 risultati\n",
        "\n",
        "# Funzione per estrarre i dati nutrizionali di un alimento\n",
        "def extract_food_data(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    food_data = []\n",
        "\n",
        "    # Modifica il selettore in base alla struttura della pagina\n",
        "    table = soup.find('table')\n",
        "    headers = []\n",
        "    if table:\n",
        "        headers = [header.text.strip() for header in table.find_all('th')]\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            food_data.append([cell.text.strip() for cell in cells])\n",
        "    else:\n",
        "        print(\"Nessuna tabella trovata.\")\n",
        "\n",
        "    return headers, food_data\n",
        "\n",
        "# Ottieni i link delle categorie di alimenti\n",
        "initial_html = get_html(base_url)\n",
        "category_links = get_recipe_links(initial_html)\n",
        "\n",
        "# Itera su ogni link di categoria per estrarre i dati nutrizionali degli alimenti\n",
        "for link in category_links:\n",
        "    category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "    category_html = get_html(category_url)\n",
        "    if category_html:\n",
        "        category_headers, food_data = extract_food_data(category_html)\n",
        "\n",
        "        # Stampa headers e food_data per ciascuna categoria\n",
        "        print(f\"Headers per {link}: {category_headers}\")\n",
        "        print(f\"Dati per {link}: {food_data}\")"
      ],
      "metadata": {
        "id": "DgNfvf9AOr3n",
        "outputId": "0d074132-965b-4edb-ae76-332a71b20d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers per /tabelle-nutrizionali/120010: ['Acciuga o alice']\n",
            "Dati per /tabelle-nutrizionali/120010: [['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120010'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, fresh, raw'], ['Parte Edibile', '75 %'], ['Porzione', '150 g']]\n",
            "Headers per /tabelle-nutrizionali/120020: [\"Acciuga o alice, sott'olio\"]\n",
            "Dati per /tabelle-nutrizionali/120020: [['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120020'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, in oil'], ['Parte Edibile', '100 %'], ['Porzione', '50 g']]\n",
            "Headers per /tabelle-nutrizionali/120030: ['Acciuga o alice, sotto sale']\n",
            "Dati per /tabelle-nutrizionali/120030: [['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120030'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, salted'], ['Parte Edibile', '50 %'], ['Porzione', '50 g']]\n",
            "Headers per /tabelle-nutrizionali/005000: ['Aglio']\n",
            "Dati per /tabelle-nutrizionali/005000: [['Categoria', 'Verdure e ortaggi'], ['Codice Alimento', '005000'], ['Nome Scientifico', 'Allium sativum'], ['English Name', 'Garlic, fresh, raw'], ['Parte Edibile', '75 %'], ['Porzione', '5 g']]\n",
            "Headers per /tabelle-nutrizionali/005004: ['Aglio Bianco Piacentino']\n",
            "Dati per /tabelle-nutrizionali/005004: [['Categoria', 'Verdure e ortaggi'], ['Codice Alimento', '005004'], ['Nome Scientifico', 'Allium sativum L.'], ['English Name', 'White Piacentino garlic, fresh, raw'], ['Informazioni', 'Prodotto inscritto nel registro dei P.A.T.'], ['Numero Campioni', '8'], ['Parte Edibile', '94 %'], ['Porzione', '3 g']]\n",
            "Headers per /tabelle-nutrizionali/005001: ['Aglio Rosso di Castelliri']\n",
            "Dati per /tabelle-nutrizionali/005001: [['Categoria', 'Verdure e ortaggi'], ['Codice Alimento', '005001'], ['Nome Scientifico', 'Allium sativum L.'], ['English Name', 'Red Castelliri garlic, fresh, raw'], ['Informazioni', 'Prodotto inscritto nel registro dei P.A.T.'], ['Numero Campioni', '8'], ['Parte Edibile', '95 %'], ['Porzione', '5 g']]\n",
            "Headers per /tabelle-nutrizionali/005002: ['Aglio Rosso di Procerno']\n",
            "Dati per /tabelle-nutrizionali/005002: [['Categoria', 'Verdure e ortaggi'], ['Codice Alimento', '005002'], ['Nome Scientifico', 'Allium sativum L.'], ['English Name', 'Red Procerno garlic, fresh, raw'], ['Informazioni', 'Prodotto inscritto nel registro dei P.A.T.'], ['Numero Campioni', '8'], ['Parte Edibile', '94 %'], ['Porzione', '4 g']]\n",
            "Headers per /tabelle-nutrizionali/005003: ['Aglio Rosso di Sulmona']\n",
            "Dati per /tabelle-nutrizionali/005003: [['Categoria', 'Verdure e ortaggi'], ['Codice Alimento', '005003'], ['Nome Scientifico', 'Allium sativum L.'], ['English Name', 'Red Sulmona garlic, fresh, raw'], ['Informazioni', 'Prodotto inscritto nel registro dei P.A.T.'], ['Numero Campioni', '8'], ['Parte Edibile', '96 %'], ['Porzione', '3 g']]\n",
            "Headers per /tabelle-nutrizionali/104033: ['Agnello, coscio, cotto, al forno']\n",
            "Dati per /tabelle-nutrizionali/104033: [['Categoria', 'Carni fresche'], ['Codice Alimento', '104033'], ['Nome Scientifico', 'Ovis agnus'], ['English Name', 'Lamb, leg, lean only, baked in oven, no salt, no fat added'], ['Informazioni', 'Tessuto muscolare privato del grasso visibile. Cottura in forno senza aggiunta di grassi e di sale'], ['Parte Edibile', '100 %'], ['Porzione', '75 g']]\n",
            "Headers per /tabelle-nutrizionali/104030: ['Agnello, coscio, crudo']\n",
            "Dati per /tabelle-nutrizionali/104030: [['Categoria', 'Carni fresche'], ['Codice Alimento', '104030'], ['Nome Scientifico', 'Ovis agnus'], ['English Name', 'Lamb, leg, lean only, raw'], ['Informazioni', 'Tessuto muscolare privato del grasso visibile'], ['Parte Edibile', '100 %'], ['Porzione', '100 g']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping da https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-categoria con file excel, ma senza dettagli nutrizionali ..."
      ],
      "metadata": {
        "id": "vUiwcIlHTz9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)  # Imposta il livello di logging\n",
        "\n",
        "BASE_URL = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-ordine-alfabetico\"\n",
        "\n",
        "def get_html(url):\n",
        "    \"\"\"\n",
        "    Ottiene il contenuto HTML di una pagina.\n",
        "\n",
        "    :param url: URL della pagina da cui ottenere l'HTML\n",
        "    :return: Contenuto HTML della pagina, o None se si verifica un errore\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Genera un'eccezione per errori HTTP\n",
        "        return response.text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Errore nella richiesta a {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_recipe_links(html):\n",
        "    \"\"\"\n",
        "    Estrae i link delle ricette dalla pagina iniziale delle categorie di alimenti.\n",
        "\n",
        "    :param html: Contenuto HTML della pagina\n",
        "    :return: Lista di link delle ricette (limitato ai primi 3 risultati)\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/tabelle-nutrizionali/'):\n",
        "            recipe_links.append(href)\n",
        "    return recipe_links[:3]\n",
        "\n",
        "def extract_food_data(html):\n",
        "    \"\"\"\n",
        "    Estrae i dati nutrizionali di un alimento dalla pagina.\n",
        "\n",
        "    :param html: Contenuto HTML della pagina\n",
        "    :return: Tuple contenente gli headers e i dati nutrizionali\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    food_data = []\n",
        "\n",
        "    table = soup.find('table')\n",
        "    headers = []\n",
        "    if table:\n",
        "        headers = [header.text.strip() for header in table.find_all('th')]\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            food_data.append([cell.text.strip() for cell in cells])\n",
        "    else:\n",
        "        logging.warning(\"Nessuna tabella trovata.\")\n",
        "    print(food_data)\n",
        "    return headers, food_data\n",
        "\n",
        "def main():\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = \"Dati Nutrizionali\"\n",
        "    sheet.append([\"Link\", \"Nome Alimento\", \"Categoria\", \"Codice Alimento\", \"Nome Scientifico\", \"English Name\", \"Parte Edibile\", \"Porzione\"])\n",
        "\n",
        "    initial_html = get_html(BASE_URL)\n",
        "    if initial_html:\n",
        "        category_links = get_recipe_links(initial_html)\n",
        "\n",
        "        for link in category_links:\n",
        "            category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "            category_html = get_html(category_url)\n",
        "            if category_html:\n",
        "                category_headers, food_data = extract_food_data(category_html)\n",
        "                logging.info(f\"Headers per {link}: {category_headers}\")\n",
        "                logging.info(f\"Dati per {link}: {food_data}\")\n",
        "\n",
        "                if food_data:\n",
        "                    full_link = f\"https://www.alimentinutrizione.it{link}\"  # Link completo\n",
        "                    row_data = [full_link, category_headers[0]]  # Link e Nome Alimento\n",
        "                    row_data.extend([item[1] for item in food_data])  # Aggiungi gli altri dati\n",
        "                    sheet.append(row_data)\n",
        "\n",
        "        workbook.save(\"dati_nutrizionali.xlsx\")\n",
        "        logging.info(\"Dati salvati in 'dati_nutrizionali.xlsx'\")\n",
        "    else:\n",
        "        logging.error(\"Impossibile ottenere il contenuto HTML dalla pagina iniziale.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iItOxVPIcYau",
        "outputId": "0e5e38f7-45c9-44e9-b1e8-cae9deb71e87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120010'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, fresh, raw'], ['Parte Edibile', '75 %'], ['Porzione', '150 g']]\n",
            "[['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120020'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, in oil'], ['Parte Edibile', '100 %'], ['Porzione', '50 g']]\n",
            "[['Categoria', 'Prodotti della pesca'], ['Codice Alimento', '120030'], ['Nome Scientifico', 'Engraulis enchrasicholus'], ['English Name', 'Anchovy, salted'], ['Parte Edibile', '50 %'], ['Porzione', '50 g']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4Vv1YE8H9zL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESTRAZIONE DEI VALORI DI DETTAGLIO DI OGNI ALIMENTO"
      ],
      "metadata": {
        "id": "311JoC5ctzo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL della pagina web da analizzare\n",
        "url = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/120010\"\n",
        "\n",
        "# Recupero della pagina web\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Verifica che la richiesta sia andata a buon fine\n",
        "\n",
        "# Parsing della pagina web con BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Lista degli elementi da estrarre\n",
        "elements_to_extract = {\n",
        "    \"Acqua (g)\": \"g\",\n",
        "    \"Energia (kcal)\": \"kcal\",\n",
        "    \"Energia (kJ)\": \"kJ\",\n",
        "    \"Proteine (g)\": \"g (N x 6,25)\",\n",
        "    \"Colesterolo (mg)\": \"mg\",\n",
        "    \"Carboidrati disponibili (g)\": \"g\",\n",
        "    \"Amido (g)\": \"g\",\n",
        "    \"Zuccheri solubili (g)\": \"g\",\n",
        "    \"Alcool (g)\": \"g\",\n",
        "    \"Fibra totale (g)\": \"g\"\n",
        "}\n",
        "\n",
        "# Dizionario per memorizzare i risultati\n",
        "results = {}\n",
        "\n",
        "# Estrazione dei dati\n",
        "for row in soup.find_all(\"tr\", class_=\"corponutriente\"):\n",
        "    cells = row.find_all(\"td\")\n",
        "    if len(cells) >= 3:\n",
        "        element_name = cells[0].get_text(strip=True)\n",
        "        if element_name in elements_to_extract:\n",
        "            element_value = cells[2].get_text(strip=True)\n",
        "            unit = elements_to_extract[element_name]\n",
        "            results[element_name] = f\"{element_value} {unit}\"\n",
        "\n",
        "# Stampa i risultati\n",
        "for element, value in results.items():\n",
        "    print(f\"{element}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp8HKiEv5a9l",
        "outputId": "660351c8-396c-438a-db84-b21fc3d6b5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acqua (g): 76.5 g\n",
            "Energia (kcal): 96 kcal\n",
            "Energia (kJ): 403 kJ\n",
            "Proteine (g): 16.8 g (N x 6,25)\n",
            "Colesterolo (mg): 61 mg\n",
            "Carboidrati disponibili (g): 1.5 g\n",
            "Amido (g): 0 g\n",
            "Zuccheri solubili (g): 1.5 g\n",
            "Alcool (g): 0 g\n",
            "Fibra totale (g): 0 g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINK CREATI CORRETAMENTE E DETTAGLI ALIMENTO SALVATI CORRETTAMENTE - MANCANO NOME ALIMENTO..."
      ],
      "metadata": {
        "id": "qEdi4cDb9xMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "BASE_URL = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-ordine-alfabetico\"\n",
        "\n",
        "def get_html(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Errore nella richiesta a {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_recipe_links(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/tabelle-nutrizionali/'):\n",
        "            recipe_links.append(href)\n",
        "    return recipe_links[:3]\n",
        "\n",
        "def extract_food_data(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    elements_to_extract = {\n",
        "        \"Acqua (g)\": \"g\",\n",
        "        \"Energia (kcal)\": \"kcal\",\n",
        "        \"Energia (kJ)\": \"kJ\",\n",
        "        \"Proteine (g)\": \"g (N x 6,25)\",\n",
        "        \"Colesterolo (mg)\": \"mg\",\n",
        "        \"Carboidrati disponibili (g)\": \"g\",\n",
        "        \"Amido (g)\": \"g\",\n",
        "        \"Zuccheri solubili (g)\": \"g\",\n",
        "        \"Alcool (g)\": \"g\",\n",
        "        \"Fibra totale (g)\": \"g\"\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for row in soup.find_all(\"tr\", class_=\"corponutriente\"):\n",
        "        cells = row.find_all(\"td\")\n",
        "        if len(cells) >= 3:\n",
        "            element_name = cells[0].get_text(strip=True)\n",
        "            if element_name in elements_to_extract:\n",
        "                element_value = cells[2].get_text(strip=True)\n",
        "                unit = elements_to_extract[element_name]\n",
        "                results[element_name] = f\"{element_value} {unit}\"\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = \"Dati Nutrizionali\"\n",
        "    sheet.append([\"Link\", \"Nome Alimento\", \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\", \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"])\n",
        "\n",
        "    initial_html = get_html(BASE_URL)\n",
        "    if initial_html:\n",
        "        category_links = get_recipe_links(initial_html)\n",
        "\n",
        "        for link in category_links:\n",
        "            category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "            category_html = get_html(category_url)\n",
        "            if category_html:\n",
        "                food_data = extract_food_data(category_html)\n",
        "                logging.info(f\"Dati per {link}: {food_data}\")\n",
        "\n",
        "                if food_data:\n",
        "                    row_data = [f\"https://www.alimentinutrizione.it{link}\"]\n",
        "                    row_data.append(food_data.get(\"Nome Alimento\", \"\"))\n",
        "                    row_data.extend([food_data.get(key, \"\") for key in [\n",
        "                        \"Acqua (g)\",\n",
        "                        \"Energia (kcal)\",\n",
        "                        \"Energia (kJ)\",\n",
        "                        \"Proteine (g)\",\n",
        "                        \"Colesterolo (mg)\",\n",
        "                        \"Carboidrati disponibili (g)\",\n",
        "                        \"Amido (g)\",\n",
        "                        \"Zuccheri solubili (g)\",\n",
        "                        \"Alcool (g)\",\n",
        "                        \"Fibra totale (g)\"\n",
        "                    ]])\n",
        "                    sheet.append(row_data)\n",
        "\n",
        "        workbook.save(\"dati_nutrizionali.xlsx\")\n",
        "        logging.info(\"Dati salvati in 'dati_nutrizionali.xlsx'\")\n",
        "    else:\n",
        "        logging.error(\"Impossibile ottenere il contenuto HTML dalla pagina iniziale.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "87PAW72hzYLT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINITO tranne porzione che deve essere sempre 100"
      ],
      "metadata": {
        "id": "13pOmJuzvY4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "BASE_URL = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-ordine-alfabetico\"\n",
        "\n",
        "def get_html(url):\n",
        "    \"\"\"\n",
        "    Ottiene il contenuto HTML di una pagina.\n",
        "\n",
        "    :param url: URL della pagina da cui ottenere l'HTML\n",
        "    :return: Contenuto HTML della pagina, o None se si verifica un errore\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Genera un'eccezione per errori HTTP\n",
        "        return response.text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Errore nella richiesta a {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_recipe_links(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/tabelle-nutrizionali/'):\n",
        "            recipe_links.append(href)\n",
        "    return recipe_links[:3]\n",
        "\n",
        "def extract_food_data(html):\n",
        "    \"\"\"\n",
        "    Estrae i dati nutrizionali e i dettagli di un alimento dalla pagina.\n",
        "\n",
        "    :param html: Contenuto HTML della pagina\n",
        "    :return: Tuple contenente gli headers, i dati nutrizionali e i dettagli dell'alimento\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    food_data = []\n",
        "\n",
        "    table = soup.find('table')\n",
        "    headers = []\n",
        "    if table:\n",
        "        headers = [header.text.strip() for header in table.find_all('th')]\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all('td')\n",
        "            food_data.append([cell.text.strip() for cell in cells])\n",
        "    else:\n",
        "        logging.warning(\"Nessuna tabella trovata.\")\n",
        "\n",
        "    # Debug print per vedere il contenuto di food_data\n",
        "    for idx, item in enumerate(food_data):\n",
        "        print(f\"Food Data {idx}: {item}\")\n",
        "\n",
        "    elements_to_extract = {\n",
        "        \"Acqua (g)\": \"g\",\n",
        "        \"Energia (kcal)\": \"kcal\",\n",
        "        \"Energia (kJ)\": \"kJ\",\n",
        "        \"Proteine (g)\": \"g (N x 6,25)\",\n",
        "        \"Colesterolo (mg)\": \"mg\",\n",
        "        \"Carboidrati disponibili (g)\": \"g\",\n",
        "        \"Amido (g)\": \"g\",\n",
        "        \"Zuccheri solubili (g)\": \"g\",\n",
        "        \"Alcool (g)\": \"g\",\n",
        "        \"Fibra totale (g)\": \"g\"\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for row in soup.find_all(\"tr\", class_=\"corponutriente\"):\n",
        "        cells = row.find_all(\"td\")\n",
        "        if len(cells) >= 3:\n",
        "            element_name = cells[0].get_text(strip=True)\n",
        "            if element_name in elements_to_extract:\n",
        "                element_value = cells[2].get_text(strip=True)\n",
        "                unit = elements_to_extract[element_name]\n",
        "                results[element_name] = f\"{element_value} {unit}\"\n",
        "\n",
        "\n",
        "    details = {\n",
        "    \"Nome Alimento\": soup.find(\"h1\", class_=\"article-title\").get_text(strip=True) if soup.find(\"h1\", class_=\"article-title\") else \"\",\n",
        "    \"Categoria\": next((item[1] for item in food_data if item[0] == \"Categoria\"), \"\"),\n",
        "    \"Codice Alimento\": next((item[1] for item in food_data if item[0] == \"Codice Alimento\"), \"\"),\n",
        "    \"Parte Edibile\": next((item[1] for item in food_data if item[0] == \"Parte Edibile\"), \"\"),\n",
        "    \"Porzione\": next((item[1] for item in food_data if item[0] == \"Porzione\"), \"\"),\n",
        "    \"Nome Scientifico\": next((item[1] for item in food_data if item[0] == \"Nome Scientifico\"), \"\")\n",
        "    }\n",
        "\n",
        "    return headers, food_data, results, details\n",
        "\n",
        "def main():\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = \"Dati Nutrizionali\"\n",
        "    sheet.append([\"Link\", \"Nome Alimento\", \"Categoria\", \"Codice Alimento\", \"Nome Scientifico\", \"Parte Edibile\", \"Porzione\", \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\", \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"])\n",
        "\n",
        "    initial_html = get_html(BASE_URL)\n",
        "    if initial_html:\n",
        "        category_links = get_recipe_links(initial_html)\n",
        "\n",
        "        for link in category_links:\n",
        "            category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "            category_html = get_html(category_url)\n",
        "            if category_html:\n",
        "                headers, food_data, results, details = extract_food_data(category_html)\n",
        "                logging.info(f\"Headers per {link}: {headers}\")\n",
        "                logging.info(f\"Dati per {link}: {food_data}\")\n",
        "                logging.info(f\"Dettagli per {link}: {details}\")\n",
        "\n",
        "                row_data = [\n",
        "                    f\"https://www.alimentinutrizione.it{link}\",\n",
        "                    details.get(\"Nome Alimento\", \"\"),\n",
        "                    details.get(\"Categoria\", \"\"),\n",
        "                    details.get(\"Codice Alimento\", \"\"),\n",
        "                    details.get(\"Nome Scientifico\", \"\"),\n",
        "                    details.get(\"Parte Edibile\", \"\"),\n",
        "                    details.get(\"Porzione\", \"\")\n",
        "                ]\n",
        "                row_data.extend([results.get(key, \"\") for key in [\n",
        "                    \"Acqua (g)\",\n",
        "                    \"Energia (kcal)\",\n",
        "                    \"Energia (kJ)\",\n",
        "                    \"Proteine (g)\",\n",
        "                    \"Colesterolo (mg)\",\n",
        "                    \"Carboidrati disponibili (g)\",\n",
        "                    \"Amido (g)\",\n",
        "                    \"Zuccheri solubili (g)\",\n",
        "                    \"Alcool (g)\",\n",
        "                    \"Fibra totale (g)\"\n",
        "                ]])\n",
        "                sheet.append(row_data)\n",
        "\n",
        "        workbook.save(\"dati_nutrizionali.xlsx\")\n",
        "        logging.info(\"Dati salvati in 'dati_nutrizionali.xlsx'\")\n",
        "    else:\n",
        "        logging.error(\"Impossibile ottenere il contenuto HTML dalla pagina iniziale.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezwP7KPb42LU",
        "outputId": "53560369-2dbd-4f3a-f58a-73a767900219"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food Data 0: ['Categoria', 'Prodotti della pesca']\n",
            "Food Data 1: ['Codice Alimento', '120010']\n",
            "Food Data 2: ['Nome Scientifico', 'Engraulis enchrasicholus']\n",
            "Food Data 3: ['English Name', 'Anchovy, fresh, raw']\n",
            "Food Data 4: ['Parte Edibile', '75 %']\n",
            "Food Data 5: ['Porzione', '150 g']\n",
            "Details: {'Nome Alimento': 'Acciuga o alice', 'Categoria': 'Prodotti della pesca', 'Codice Alimento': '120010', 'Parte Edibile': '75 %', 'Porzione': '150 g', 'Nome Scientifico': 'Engraulis enchrasicholus'}\n",
            "Food Data 0: ['Categoria', 'Prodotti della pesca']\n",
            "Food Data 1: ['Codice Alimento', '120020']\n",
            "Food Data 2: ['Nome Scientifico', 'Engraulis enchrasicholus']\n",
            "Food Data 3: ['English Name', 'Anchovy, in oil']\n",
            "Food Data 4: ['Parte Edibile', '100 %']\n",
            "Food Data 5: ['Porzione', '50 g']\n",
            "Details: {'Nome Alimento': \"Acciuga o alice, sott'olio\", 'Categoria': 'Prodotti della pesca', 'Codice Alimento': '120020', 'Parte Edibile': '100 %', 'Porzione': '50 g', 'Nome Scientifico': 'Engraulis enchrasicholus'}\n",
            "Food Data 0: ['Categoria', 'Prodotti della pesca']\n",
            "Food Data 1: ['Codice Alimento', '120030']\n",
            "Food Data 2: ['Nome Scientifico', 'Engraulis enchrasicholus']\n",
            "Food Data 3: ['English Name', 'Anchovy, salted']\n",
            "Food Data 4: ['Parte Edibile', '50 %']\n",
            "Food Data 5: ['Porzione', '50 g']\n",
            "Details: {'Nome Alimento': 'Acciuga o alice, sotto sale', 'Categoria': 'Prodotti della pesca', 'Codice Alimento': '120030', 'Parte Edibile': '50 %', 'Porzione': '50 g', 'Nome Scientifico': 'Engraulis enchrasicholus'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codice ottimizzato:"
      ],
      "metadata": {
        "id": "HOPMZHkZsIvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp beautifulsoup4 openpyxl cachetools nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978Xf3CEtOF7",
        "outputId": "e50cb0a0-66e9-48c1-be1a-8944df8feb4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.9.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (5.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importazione delle librerie necessarie\n",
        "import aiohttp  # Per le richieste HTTP asincrone\n",
        "import asyncio  # Per la programmazione asincrona\n",
        "from bs4 import BeautifulSoup  # Per il parsing HTML\n",
        "import openpyxl  # Per la creazione di file Excel\n",
        "import logging  # Per il logging delle informazioni\n",
        "from cachetools import TTLCache  # Per la memorizzazione temporanea dei dati\n",
        "import time  # Per misurare il tempo di esecuzione\n",
        "import nest_asyncio  # Per permettere l'esecuzione di loop asyncio annidati\n",
        "\n",
        "# Applica nest_asyncio per permettere l'esecuzione di loop annidati in ambienti come Jupyter Notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configurazione del logging per visualizzare le informazioni durante l'esecuzione\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# URL di base del sito web da cui estrarre i dati\n",
        "BASE_URL = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-ordine-alfabetico\"\n",
        "\n",
        "# Creazione di una cache per memorizzare le pagine HTML scaricate (durata: 1 ora)\n",
        "html_cache = TTLCache(maxsize=100, ttl=3600)\n",
        "\n",
        "async def get_html(session, url):\n",
        "    \"\"\"\n",
        "    Funzione asincrona per ottenere il contenuto HTML di una pagina web.\n",
        "    Usa una cache per evitare di scaricare più volte la stessa pagina.\n",
        "    \"\"\"\n",
        "    if url in html_cache:\n",
        "        return html_cache[url]  # Restituisce la versione in cache se disponibile\n",
        "\n",
        "    try:\n",
        "        async with session.get(url) as response:\n",
        "            response.raise_for_status()  # Solleva un'eccezione per errori HTTP\n",
        "            html = await response.text()  # Ottiene il contenuto HTML\n",
        "            html_cache[url] = html  # Memorizza il contenuto nella cache\n",
        "            return html\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Errore nella richiesta a {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_recipe_links(html):\n",
        "    \"\"\"\n",
        "    Estrae i link delle ricette dalla pagina HTML principale.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = [link['href'] for link in soup.select('a[href^=\"/tabelle-nutrizionali/\"]')]\n",
        "    return recipe_links[:3]  # Restituisce solo i primi 3 link per limitare l'esecuzione\n",
        "\n",
        "def extract_food_data(html):\n",
        "    \"\"\"\n",
        "    Estrae i dati nutrizionali e i dettagli dell'alimento dalla pagina HTML.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Estrazione dei dettagli dell'alimento\n",
        "    details = {\n",
        "        \"Nome Alimento\": soup.select_one(\"h1.article-title\").text.strip() if soup.select_one(\"h1.article-title\") else \"\",\n",
        "        \"Categoria\": soup.select_one('td:-soup-contains(\"Categoria\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Categoria\") + td') else \"\",\n",
        "        \"Codice Alimento\": soup.select_one('td:-soup-contains(\"Codice Alimento\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Codice Alimento\") + td') else \"\",\n",
        "        \"Parte Edibile\": soup.select_one('td:-soup-contains(\"Parte Edibile\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Parte Edibile\") + td') else \"\",\n",
        "        \"Porzione\": soup.select_one('td:-soup-contains(\"Porzione\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Porzione\") + td') else \"\",\n",
        "        \"Nome Scientifico\": soup.select_one('td:-soup-contains(\"Nome Scientifico\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Nome Scientifico\") + td') else \"\"\n",
        "    }\n",
        "\n",
        "    # Lista degli elementi nutrizionali da estrarre\n",
        "    elements_to_extract = [\n",
        "        \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "        \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"\n",
        "    ]\n",
        "\n",
        "    # Estrazione dei valori nutrizionali\n",
        "    results = {}\n",
        "    for element in elements_to_extract:\n",
        "        value_cell = soup.select_one(f'td:-soup-contains(\"{element}\") ~ td:nth-of-type(3)')\n",
        "        if value_cell:\n",
        "            results[element] = value_cell.text.strip()\n",
        "        else:\n",
        "            results[element] = \"\"\n",
        "\n",
        "    return details, results\n",
        "\n",
        "async def process_category(session, link):\n",
        "    \"\"\"\n",
        "    Funzione asincrona per processare una singola categoria di alimenti.\n",
        "    \"\"\"\n",
        "    category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "    category_html = await get_html(session, category_url)\n",
        "    if category_html:\n",
        "        details, results = extract_food_data(category_html)\n",
        "        logging.info(f\"Dati estratti per {link}\")\n",
        "        return link, details, results\n",
        "    return None\n",
        "\n",
        "async def main():\n",
        "    \"\"\"\n",
        "    Funzione principale asincrona che coordina l'estrazione dei dati e la creazione del file Excel.\n",
        "    \"\"\"\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = \"Dati Nutrizionali\"\n",
        "\n",
        "    # Aggiunge l'intestazione al foglio Excel\n",
        "    sheet.append([\"Link\", \"Nome Alimento\", \"Categoria\", \"Codice Alimento\", \"Nome Scientifico\", \"Parte Edibile\", \"Porzione\",\n",
        "                  \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "                  \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"])\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        initial_html = await get_html(session, BASE_URL)\n",
        "        if initial_html:\n",
        "            category_links = get_recipe_links(initial_html)\n",
        "\n",
        "            # Crea e esegue le attività asincrone per ogni categoria\n",
        "            tasks = [process_category(session, link) for link in category_links]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Elabora i risultati e li aggiunge al foglio Excel\n",
        "            for result in results:\n",
        "                if result:\n",
        "                    link, details, nutrients = result\n",
        "                    row_data = [\n",
        "                        f\"https://www.alimentinutrizione.it{link}\",\n",
        "                        details.get(\"Nome Alimento\", \"\"),\n",
        "                        details.get(\"Categoria\", \"\"),\n",
        "                        details.get(\"Codice Alimento\", \"\"),\n",
        "                        details.get(\"Nome Scientifico\", \"\"),\n",
        "                        details.get(\"Parte Edibile\", \"\"),\n",
        "                        details.get(\"Porzione\", \"\")\n",
        "                    ]\n",
        "                    row_data.extend([nutrients.get(key, \"\") for key in [\n",
        "                        \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "                        \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"\n",
        "                    ]])\n",
        "                    sheet.append(row_data)\n",
        "\n",
        "    # Salva il file Excel\n",
        "    workbook.save(\"dati_nutrizionali.xlsx\")\n",
        "    logging.info(\"Dati salvati in 'dati_nutrizionali.xlsx'\")\n",
        "\n",
        "async def run_main():\n",
        "    \"\"\"\n",
        "    Funzione wrapper per eseguire main() e misurare il tempo di esecuzione.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    await main()\n",
        "    end_time = time.time()\n",
        "    logging.info(f\"Tempo di esecuzione totale: {end_time - start_time:.2f} secondi\")\n",
        "\n",
        "def execute_async():\n",
        "    \"\"\"\n",
        "    Funzione per eseguire il codice asincrono in un ambiente sincrono (come Jupyter Notebook).\n",
        "    \"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(run_main())\n",
        "\n",
        "# Istruzioni per l'esecuzione\n",
        "print(\"Per eseguire lo script, usa: execute_async()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kqLszxEtUEo",
        "outputId": "8b536467-51ca-4c89-85be-bc814972b546"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per eseguire lo script, usa: execute_async()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''stesso codice con Header con User-Agent per imitare un browser reale + sleep tra chiamate '''\n",
        "\n",
        "import aiohttp\n",
        "import asyncio\n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "import logging\n",
        "from cachetools import TTLCache\n",
        "import time\n",
        "import nest_asyncio\n",
        "import random\n",
        "\n",
        "# Applica nest_asyncio per permettere l'esecuzione di loop asyncio annidati\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configurazione del logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# URL di base del sito web da cui estrarre i dati\n",
        "BASE_URL = \"https://www.alimentinutrizione.it/tabelle-nutrizionali/ricerca-per-ordine-alfabetico\"\n",
        "\n",
        "# Cache per memorizzare le pagine HTML scaricate (durata: 1 ora)\n",
        "html_cache = TTLCache(maxsize=100, ttl=3600)\n",
        "\n",
        "# Header con User-Agent per imitare un browser reale\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "async def get_html(session, url):\n",
        "    \"\"\"\n",
        "    Funzione asincrona per ottenere il contenuto HTML di una pagina web.\n",
        "    Usa una cache per evitare di scaricare più volte la stessa pagina.\n",
        "    Include un delay casuale e un User-Agent nell'header.\n",
        "    \"\"\"\n",
        "    if url in html_cache:\n",
        "        return html_cache[url]\n",
        "\n",
        "    # Aggiunge un delay casuale tra 0 e 1 secondi\n",
        "    await asyncio.sleep(random.uniform(0, 1))\n",
        "\n",
        "    try:\n",
        "        async with session.get(url, headers=HEADERS) as response:\n",
        "            response.raise_for_status()\n",
        "            html = await response.text()\n",
        "            html_cache[url] = html\n",
        "            return html\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Errore nella richiesta a {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_recipe_links(html):\n",
        "    \"\"\"\n",
        "    Estrae i link delle ricette dalla pagina HTML principale.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    recipe_links = [link['href'] for link in soup.select('a[href^=\"/tabelle-nutrizionali/\"]')]\n",
        "    return recipe_links\n",
        "\n",
        "def extract_food_data(html):\n",
        "    \"\"\"\n",
        "    Estrae i dati nutrizionali e i dettagli dell'alimento dalla pagina HTML.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    details = {\n",
        "        \"Nome Alimento\": soup.select_one(\"h1.article-title\").text.strip() if soup.select_one(\"h1.article-title\") else \"\",\n",
        "        \"Categoria\": soup.select_one('td:-soup-contains(\"Categoria\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Categoria\") + td') else \"\",\n",
        "        \"Codice Alimento\": soup.select_one('td:-soup-contains(\"Codice Alimento\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Codice Alimento\") + td') else \"\",\n",
        "        \"Parte Edibile\": soup.select_one('td:-soup-contains(\"Parte Edibile\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Parte Edibile\") + td') else \"\",\n",
        "        \"Porzione\": soup.select_one('td:-soup-contains(\"Porzione\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Porzione\") + td') else \"\",\n",
        "        \"Nome Scientifico\": soup.select_one('td:-soup-contains(\"Nome Scientifico\") + td').text.strip() if soup.select_one('td:-soup-contains(\"Nome Scientifico\") + td') else \"\"\n",
        "    }\n",
        "\n",
        "    elements_to_extract = [\n",
        "        \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "        \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "    for element in elements_to_extract:\n",
        "        value_cell = soup.select_one(f'td:-soup-contains(\"{element}\") ~ td:nth-of-type(3)')\n",
        "        if value_cell:\n",
        "            results[element] = value_cell.text.strip()\n",
        "        else:\n",
        "            results[element] = \"\"\n",
        "\n",
        "    return details, results\n",
        "\n",
        "async def process_category(session, link):\n",
        "    \"\"\"\n",
        "    Funzione asincrona per processare una singola categoria di alimenti.\n",
        "    \"\"\"\n",
        "    category_url = f\"https://www.alimentinutrizione.it{link}\"\n",
        "    category_html = await get_html(session, category_url)\n",
        "    if category_html:\n",
        "        details, results = extract_food_data(category_html)\n",
        "        logging.info(f\"Dati estratti per {link}\")\n",
        "        return link, details, results\n",
        "    return None\n",
        "\n",
        "async def main():\n",
        "    \"\"\"\n",
        "    Funzione principale asincrona che coordina l'estrazione dei dati e la creazione del file Excel.\n",
        "    \"\"\"\n",
        "    workbook = openpyxl.Workbook()\n",
        "    sheet = workbook.active\n",
        "    sheet.title = \"Dati Nutrizionali\"\n",
        "\n",
        "    sheet.append([\"Link\", \"Nome Alimento\", \"Categoria\", \"Codice Alimento\", \"Nome Scientifico\", \"Parte Edibile\", \"Porzione\",\n",
        "                  \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "                  \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"])\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        initial_html = await get_html(session, BASE_URL)\n",
        "        if initial_html:\n",
        "            category_links = get_recipe_links(initial_html)\n",
        "\n",
        "            for link in category_links:\n",
        "                result = await process_category(session, link)\n",
        "                if result:\n",
        "                    link, details, nutrients = result\n",
        "                    row_data = [\n",
        "                        f\"https://www.alimentinutrizione.it{link}\",\n",
        "                        details.get(\"Nome Alimento\", \"\"),\n",
        "                        details.get(\"Categoria\", \"\"),\n",
        "                        details.get(\"Codice Alimento\", \"\"),\n",
        "                        details.get(\"Nome Scientifico\", \"\"),\n",
        "                        details.get(\"Parte Edibile\", \"\"),\n",
        "                        details.get(\"Porzione\", \"\")\n",
        "                    ]\n",
        "                    row_data.extend([nutrients.get(key, \"\") for key in [\n",
        "                        \"Acqua (g)\", \"Energia (kcal)\", \"Energia (kJ)\", \"Proteine (g)\", \"Colesterolo (mg)\",\n",
        "                        \"Carboidrati disponibili (g)\", \"Amido (g)\", \"Zuccheri solubili (g)\", \"Alcool (g)\", \"Fibra totale (g)\"\n",
        "                    ]])\n",
        "                    sheet.append(row_data)\n",
        "\n",
        "    workbook.save(\"dati_nutrizionali.xlsx\")\n",
        "    logging.info(\"Dati salvati in 'dati_nutrizionali.xlsx'\")\n",
        "\n",
        "async def run_main():\n",
        "    \"\"\"\n",
        "    Funzione wrapper per eseguire main() e misurare il tempo di esecuzione.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    await main()\n",
        "    end_time = time.time()\n",
        "    logging.info(f\"Tempo di esecuzione totale: {end_time - start_time:.2f} secondi\")\n",
        "\n",
        "def execute_async():\n",
        "    \"\"\"\n",
        "    Funzione per eseguire il codice asincrono in un ambiente sincrono (come Jupyter Notebook).\n",
        "    \"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(run_main())\n",
        "\n",
        "# Istruzioni per l'esecuzione\n",
        "print(\"Per eseguire lo script, usa: execute_async()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PulcjVTfx_UJ",
        "outputId": "33dd5e2c-d004-48a7-de81-800b7611de2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per eseguire lo script, usa: execute_async()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execute_async()"
      ],
      "metadata": {
        "id": "nAN9-o8zuQCP"
      },
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-f1avGJMTkTD",
        "311JoC5ctzo0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
